{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Purchase Prediction\n",
    "\n",
    "What if you know if a customer is likely to make another purchase in 7 days?\n",
    "\n",
    "You can build your strategy on top of that and come up with lots of tactical actions like:\n",
    "\n",
    "- No promotional offer to this customer since s/he will make a purchase anyways\n",
    "- Nudge the customer with inbound marketing if there is no purchase in the predicted time window (or fire the guy who did the prediction) \n",
    "\n",
    "**Outilne** \n",
    "\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "- Drowing a conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for the analysis was taken from [kaggle](https://www.kaggle.com/mkechinov/ecommerce-purchase-history-from-jewelry-store)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pachages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import date\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data = pd.read_csv('data/events.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user_session', 'product_id', 'category_id', 'user_id']\n",
    "\n",
    "for col in cols: \n",
    "    data[col] = data[col].astype('O')\n",
    "    \n",
    "data['event_time'] = pd.to_datetime(data['event_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start with a quick exploratory data analysis. Describe the plots and draw conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continuous(dataset, var_name):\n",
    "    sns.displot(dataset[var_name])\n",
    "    plt.axvline(dataset[var_name].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(dataset[var_name].median(), color='r', linewidth=1)\n",
    "    plt.title(f'Distribution of variable \"{var_name}\"')\n",
    "    \n",
    "def plot_objects(dataset, var_name):\n",
    "    sns.countplot(dataset[var_name])\n",
    "    plt.title(f'Distribution of variable \"{var_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous(data, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous(data[data['price'] < 3000], 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_objects(data, 'brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_objects(data, 'event_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.event_type=='view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.event_time.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use 5 months of data to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purch_hist = data[(data.event_time < '2021-01-31')]\n",
    "purch_next = data[(data.event_time >= '2021-01-31')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer  = pd.DataFrame(purch_hist['user_id'].unique())\n",
    "customer.columns = ['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purch_hist.shape, purch_next.shape, customer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = purch_next.groupby('user_id').event_time.min().reset_index()\n",
    "next_.columns = ['user_id','MinNextPurchase']\n",
    "next_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ = purch_hist.groupby('user_id').event_time.max().reset_index()\n",
    "last_.columns = ['user_id','MaxHistPurchase']\n",
    "purchase = pd.merge(last_, next_,on='user_id',how='left')\n",
    "purchase['NextPurchaseDay'] = (purchase['MinNextPurchase'] - purchase['MaxHistPurchase']).dt.days\n",
    "purchase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.merge(customer, purchase[['user_id','NextPurchaseDay']],on='user_id',how='left')\n",
    "print('Number of retained customers: ', customer.NextPurchaseDay.notna().sum())\n",
    "customer = customer.fillna(-1)\n",
    "customer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.sort_values(by='NextPurchaseDay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order = purch_hist[['user_id','event_time']]\n",
    "day_order = day_order.sort_values(['user_id','event_time'])\n",
    "day_order = day_order.drop_duplicates(subset=['user_id','event_time'],keep='first')\n",
    "\n",
    "# last 3 purchase dates\n",
    "day_order['Previous'] = day_order.groupby('user_id')['event_time'].shift(1)\n",
    "day_order['Previous2'] = day_order.groupby('user_id')['event_time'].shift(2)\n",
    "day_order['Previous3'] = day_order.groupby('user_id')['event_time'].shift(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nas = pd.DataFrame(day_order.isna().sum(), columns=['Number of NAs'])\n",
    "data_nas['Percentage of NAs'] = round(data_nas['Number of NAs'] / day_order.shape[0] *100, 3)\n",
    "data_nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order['DayDiff'] = (day_order['event_time'] - day_order['Previous']).dt.days\n",
    "day_order['DayDiff2'] = (day_order['event_time'] - day_order['Previous2']).dt.days\n",
    "day_order['DayDiff3'] = (day_order['event_time'] - day_order['Previous3']).dt.days\n",
    "day_order.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_diff = day_order.groupby('user_id').agg({'DayDiff': ['mean','std']}).reset_index()\n",
    "day_diff.columns = ['user_id', 'DayDiffMean','DayDiffStd']\n",
    "day_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = day_order.drop_duplicates(subset=['user_id'],keep='last')\n",
    "last_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_day = pd.merge(last_day, day_diff, on='user_id')\n",
    "customer = pd.merge(customer, last_day[['user_id','DayDiff', 'DayDiff2','DayDiffMean','DayDiffStd']], on='user_id')\n",
    "customer = customer.fillna(-1)\n",
    "\n",
    "\n",
    "len(customer)\n",
    "# USE 'DayDiff3' in case you have more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = data.groupby('user_id', as_index=False)['price'].mean()\n",
    "#Add more if you have other handy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(customer, other_features, on= 'user_id', how = 'left')\n",
    "\n",
    "final.set_index('user_id', inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: make a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model we are going to create labels for dataset. This may help to predict churn as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1 = final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1.NextPurchaseDay.describe()\n",
    "\n",
    "# Use final.NextPurchaseDay.describe(np.linspace(0,1,10)) to get percentiles of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1[final_v1['NextPurchaseDay'] > -1]['NextPurchaseDay'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1['NextPurchase'] = 2 # returnd after 25 days\n",
    "final_v1.loc[final_v1.NextPurchaseDay < 31,'NextPurchase'] = 1 #returned within 25 days\n",
    "final_v1.loc[final_v1.NextPurchaseDay == -1,'NextPurchase'] = 0 #never retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1.NextPurchase.value_counts()/len(customer)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1 = final_v1.drop(columns='NextPurchaseDay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have very imbalanced data. [Some of the techniques were covered in our last tutorial](https://github.com/LilitYolyan/customer_behavior_analysis/blob/master/Week_6_Churn_Analysis_Prediction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = final_v1.drop('NextPurchase',axis=1), final_v1.NextPurchase\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Classification only on retained customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will only use those customers data who have not left. Thus, we can get a more accurate model and solve the problem of imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained = final[final['NextPurchaseDay'] != -1]\n",
    "retained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained.NextPurchaseDay.describe(percentiles=[0.33, 0.66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retained['NextPurchase'] = 2 # returned after 275\n",
    "retained.loc[retained.NextPurchaseDay < 33,'NextPurchase'] = 1 #returned within 158 and 275 days\n",
    "retained.loc[retained.NextPurchaseDay < 11,'NextPurchase'] = 0 # returned within 0 and 158 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained = retained.drop(columns='NextPurchaseDay')\n",
    "retained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained.NextPurchase.value_counts()/len(retained)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = retained.drop('NextPurchase',axis=1), retained.NextPurchase\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([x for x in range(len(clf.feature_importances_))], clf.feature_importances_)\n",
    "names = plt.xticks(np.arange(5), retained.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters which define the model architecture are referred to as hyperparameters and thus this process of searching for the ideal model architecture is referred to as hyperparameter tuning.\n",
    "\n",
    "Hyperparameters are not model parameters and they cannot be directly trained from the data. Model parameters are learned during training when we optimize a loss function using something like gradient descent.The process for learning parameter values is shown generally below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 6, 7, 8, 9],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, verbose=True)\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
