{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules for Market Basket Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association rule analysis attempts to find sets of informative patterns from large, sparse data sets. The basic idea of association rule mining is this: when events occur together more often than one would expect from their individual rates of occurrence, such cooccurrence is an interesting pattern. \n",
    "<br>\n",
    "<br>\n",
    "**Some terms to understand for association rules**\n",
    "- An *association* is simply the co-occurrence of two or more things.\n",
    "<br> Hot dogs might be positively associated with relish, hot dog buns, soda, potato chips, and ketchup.\n",
    "- A *set of items* is a group of one or more items, and might be written as {item1, item2, ...}. \n",
    "<br> For instance, a set might be {relish} or {hot dogs, soda, potato chips}.\n",
    "- A *transaction* is a set of items that co-occur in an observation. In marketing, a common transaction is the *market basket*, the set of things that are purchased or considered for purchase at one time.\n",
    "- A *rule* expresses the incidence across transactions of one set of items as a condition of another set of items.\n",
    "<br> The association of relish, conditional on hot dogs, is expressed in the rule {relish} ⇒ {hot dogs}.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Some metrics to understand for association rules**\n",
    "<br>\n",
    "- The **support** for a set of items is the proportion of all transactions that contain the set.\n",
    "<br> If {hot dogs, soda} appears in 10 out of 200 transactions, then support ({hotdogs, soda}) = 0.05.\n",
    "<br>\n",
    "<br>\n",
    "- **Confidence** is the support for the co-occurrence of all items in a rule, conditional on the support for the left hand set alone.\n",
    "\\begin{equation*} confidence(X ⇒ Y ) = \\frac {support (X ∩ Y )}{support(X)} \\end{equation*}\n",
    "<br>\n",
    "If {relish} occurs in 1% of transactions (in other words, support ({relish}) = 0.01) and {relish, hot dogs} appears in 0.5%,\n",
    "then confidence({relish} ⇒ {hotdogs}) = 0.005/0.1 = 0.5. In other words, hot dogs appear alongside relish 50% of the time that relish appears.\n",
    "<br>\n",
    "<br>\n",
    "- **Lift** is the support of a set conditional on the joint support of each element.\n",
    "\\begin{equation*}  lift (X ⇒ Y ) = \\frac {support (X ∩ Y )}{(support (X) * support (Y ))}\\end{equation*}\n",
    "\n",
    "<br>\n",
    "To continue the hot dog example, if support ({relish}) = 0.01, support ({hotdogs}) = 0.01, and support ({relish, hotdogs}) = 0.005, then lift ({relish ⇒ hotdogs}) = 0.005/(0.01 ∗ 0.01) = 50. In other words, the combination {relish, hot dogs} occurs 50 times more often than we would expect if the two items were independent.\n",
    "<br>\n",
    "<br>\n",
    "When we search for rules we wish to exceed a minimum threshold on each: to find item sets that occur relatively frequently\n",
    "in transactions (support), that showstrong conditional relationships (confidence), and that are more common than chance (lift).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For instance, if item A and B are bought together more frequently then several steps can be taken to increase the profit. For example:*\n",
    "\n",
    "- A and B can be placed together so that when a customer buys one of the product he doesn't have to go far away to buy the other product.\n",
    "- People who buy one of the products can be targeted through an advertisement campaign to buy the other.\n",
    "- Collective discounts can be offered on these products if the customer buys both of them.\n",
    "- Both A and B can be packaged together.\n",
    "\n",
    "**Apriori algorithm**\n",
    "<br> <br>\n",
    "Apriori is an algorithm for frequent item set mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.\n",
    "\n",
    "**Theory of Apriori Algorithm**\n",
    "<br>\n",
    "<br>\n",
    "For large sets of data, there can be hundreds of items in hundreds of thousands transactions. The Apriori algorithm tries to extract rules for each possible combination of items. For instance, Lift can be calculated for item 1 and item 2, item 1 and item 3, item 1 and item 4 and then item 2 and item 3, item 2 and item 4 and then combinations of items e.g. item 1, item 2 and item 3; similarly item 1, item2, and item 4, and so on.\n",
    "\n",
    "As you can see from the above example, this process can be extremely slow due to the number of combinations. To speed up the process, we need to perform the following steps:\n",
    "\n",
    "- Set a minimum value for support and confidence. This means that we are only interested in finding rules for the items that have certain default existence (e.g. support) and have a minimum value for co-occurrence with other items (e.g. confidence).\n",
    "- Extract all the subsets having higher value of support than minimum threshold.\n",
    "- Select all the rules from the subsets with confidence value higher than minimum threshold.\n",
    "- Order the rules by descending order of Lift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other datasets that can be used for analysis: \n",
    "- https://www.kaggle.com/gorkhachatryan01/purchase-behaviour \n",
    "- https://www.kaggle.com/irfanasrullah/groceries \n",
    "- https://www.kaggle.com/roshansharma/market-basket-optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = pd.read_csv('data/groceries_groceries.csv')\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data.drop(['Item(s)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "wordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(store_data['Item 1']))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Most Popular Items',fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "store_data['Item 1'].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular items', fontsize = 20)\n",
    "plt.xticks(rotation = 90 )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Apriori library we are going to use requires our dataset to be in the form of a list of lists, where the whole dataset is a big list and each transaction in the dataset is an inner list within the outer big list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(0, store_data.shape[0]):\n",
    "    records.append([str(store_data.values[i,j]) for j in range(0, store_data.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we want rules for only those items that are purchased at least 5 times a day, or 7 x 5 = 35 times in one week, since our dataset is for a one-week time period. The support for those items can be calculated as 35/9835 = 0.0035. The minimum confidence for the rules is 20% or 0.2. Similarly, we specify the value for lift as 3 and finally min_length is 2 since we want at least two products in our rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(records, min_support=0.0035, min_confidence=0.2, min_lift=2, min_length=2)\n",
    "association_results = list(association_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support value for the first rule is 0.0073. This number is calculated by dividing the number of transactions containing other vegetables divided by total number of transactions. The confidence level for the rule is 0.414 which shows that out of all the transactions that contain other vegetables, 41.4% of the transactions also contain baking powder. Finally, the lift of 2.14 tells us that baking powder is 4.84 times more likely to be bought by the customers who buy other vegetables compared to the default likelihood of the sale of baking powder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in association_results:\n",
    "\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"Rule: \" + items[0] + \" -> \" + items[1])\n",
    "    print(\"Support: \" + str(item[1]))\n",
    "    print(\"Confidence: \" + str(item[2][0][2]))\n",
    "    print(\"Lift: \" + str(item[2][0][3]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
