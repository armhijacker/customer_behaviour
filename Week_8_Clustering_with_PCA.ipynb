{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we are going to create several clustering algorithms and, most importantly, analyze and interpret the result. We are going to use cleaned and preprocessed data from our first class. However, the data is not yet fully ready for use. We need to convert it to a customer level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('data/data_cleared.csv')\n",
    "\n",
    "data['InvoiceNo'] = data['InvoiceNo'].astype('O')\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, we are going to create an RFM table as we did [in the previous lesson.](https://github.com/LilitYolyan/customer_behavior_analysis/blob/master/Week_4_Basics_of_Segmentation_RFM.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RFM\n",
    "dt = data.groupby(['CustomerID', 'InvoiceDate'], as_index=False)['TotalPrice'].sum()\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime(2011,12,10)\n",
    "\n",
    "rfm= dt.groupby('CustomerID').agg({'InvoiceDate': lambda date: (now - date.max()).days,\n",
    "                                     'CustomerID': 'count',\n",
    "                                     'TotalPrice': 'mean'})\n",
    "\n",
    "rfm.columns=['recency', 'frequency', 'monetary',]\n",
    "rfm.reset_index(inplace=True)\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute Pearson correlation coefficient for the features in our data set.\n",
    "plt.figure(figsize = (10, 8))\n",
    "s = sns.heatmap(rfm.corr(),\n",
    "               annot = True, \n",
    "               cmap = 'RdBu',\n",
    "               vmin = -1, \n",
    "               vmax = 1)\n",
    "\n",
    "s.set_yticklabels(s.get_yticklabels(), rotation = 0, fontsize = 12)\n",
    "s.set_xticklabels(s.get_xticklabels(), rotation = 90, fontsize = 12)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "cluster_data = rfm.drop(columns='CustomerID')\n",
    "scaler = StandardScaler()\n",
    "data_stand = scaler.fit_transform(cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some more features and see if the results are changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data.groupby(['CustomerID', 'InvoiceDate'], as_index=False).agg({'TotalPrice': 'sum', \n",
    "                                                                      'Quantity' : 'sum', \n",
    "                                                                      \"InvoiceNo\" : 'count'})\n",
    "\n",
    "customer_data = dt.groupby(['CustomerID']).agg(AvgQuantity = ('Quantity', 'mean'), \n",
    "                                               AvgDifferentProducts = ('InvoiceNo', 'mean'),\n",
    "                                               Recency = ('InvoiceDate', lambda date: (now - date.max()).days),\n",
    "                                               Frequency = ('CustomerID', 'count'),\n",
    "                                               Monetary_Value = ('TotalPrice', 'mean'),\n",
    "                                               GapBetweenOrders = ('InvoiceDate', lambda date: (date.max() - date.min()).days)\n",
    "                                              )\n",
    "\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stand = scaler.fit_transform(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ${\\textbf{PCA}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(data_stand)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "plt.plot(range(1,7), pca.explained_variance_ratio_.cumsum(), marker = 'o', linestyle = '--')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the rule of thumb, 80% explained variance is a good choice for PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "pca.fit(data_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ${\\textbf{PCA Results}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_comp = pd.DataFrame(data = pca.components_,\n",
    "                           columns = customer_data.columns.values,\n",
    "                           index = ['Component 1', 'Component 2', 'Component 3'])\n",
    "df_pca_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_pca_comp,\n",
    "            vmin = -1, \n",
    "            vmax = 1,\n",
    "            cmap = 'RdBu',\n",
    "            annot = True)\n",
    "plt.yticks([0, 1, 2], \n",
    "           ['Component 1', 'Component 2', 'Component 3'],\n",
    "           rotation = 45,\n",
    "           fontsize = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = pca.transform(data_stand)\n",
    "pca_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ${\\textbf{K-means clustering with PCA}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit K means using the transformed data from the PCA.\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans_pca = KMeans(n_clusters = i, random_state = 42)\n",
    "    kmeans_pca.fit(pca_results)\n",
    "    wcss.append(kmeans_pca.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Within Cluster Sum of Squares for the K-means PCA model. Here we make a decission about the number of clusters.\n",
    "# Again it looks like four is the best option.\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(range(1, 11), wcss, marker = 'o', linestyle = '--')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('K-means with PCA Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
    "kmeans_pca.fit(pca_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_frame = pd.DataFrame(pca_results, columns=['Component 1', 'Component 2', 'Component 3'])\n",
    "final_data = pd.concat([customer_data.reset_index(drop = True), pca_frame],  axis = 1)\n",
    "final_data['Segments'] = kmeans_pca.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_labels = customer_data.copy()\n",
    "segm_labels['Segments'] = kmeans_pca.labels_\n",
    "segm_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling = final_data.groupby(['Segments'], as_index=False).mean()\n",
    "\n",
    "profiling['Segment_size'] = final_data.groupby(['Segments'])['Segments'].count()\n",
    "profiling['Segment_prop'] = round(profiling['Segment_size'] / profiling['Segment_size'].sum() * 100, 2)\n",
    "\n",
    "profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the segment labels to our table\n",
    "profiling['Segments'] = profiling['Segments'].map({0:'promising', \n",
    "                                                   1:'new_and_promising',\n",
    "                                                   2:'champions', \n",
    "                                                   3:'lost'})\n",
    "\n",
    "profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the segment labels to our table\n",
    "final_data['Segments'] = final_data['Segments'].map({0:'promising', \n",
    "                                                   1:'new_and_promising',\n",
    "                                                   2:'champions', \n",
    "                                                   3:'lost'})\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = final_data['Component 2']\n",
    "y_axis = final_data['Component 1']\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.scatterplot(x_axis, y_axis, hue = final_data['Segments'], palette = ['g', 'r', 'c', 'm'])\n",
    "plt.title('Clusters by PCA Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, PCA helps to get better quality segments with clearer differences. We can now use these segments to create a better business strategy or make more personalized decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
