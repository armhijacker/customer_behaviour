{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc1976e",
   "metadata": {},
   "source": [
    "## Anomaly/Outlier Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da8ab8",
   "metadata": {},
   "source": [
    "What Is Anomaly Detection?\n",
    "\n",
    "Anomaly detection is a method used to detect something that doesn’t fit the normal behavior of a dataset. In other words, anomaly detection finds data points in a dataset that deviates from the rest of the data.\n",
    "\n",
    "Those unusual things are called outliers, peculiarities, exceptions, surprise and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5cb08",
   "metadata": {},
   "source": [
    "### Different Types of Anomalies:\n",
    "\n",
    "* Point anomalies – if a data point is too far from the rest, it falls into the category of point anomalies. The above example of bank transaction illustrates point anomalies.\n",
    "* Contextual anomalies – If the event is anomalous for specific circumstances (context), then we have contextual anomalies. As data becomes more and more complex, it is vital to use anomaly detection methods for the context. This anomaly type is common in time-series data. Example – spending $10 on ice-cream every day during the hot months is normal, but is odd for the rest months.\n",
    "* Collective anomalies. The collective anomaly denotes a collection of anomalous with respect to the whole dataset, but not individual objects. Example: breaking rhythm in ECG (Electrocardiogram)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6684c6b",
   "metadata": {},
   "source": [
    "### Supervised\n",
    "Training data is labeled with “nominal” or “anomaly”.\n",
    "\n",
    "The supervised setting is the ideal setting. It is the instance when a dataset comes neatly prepared for the data scientist with all data points labeled as anomaly or nominal. In this case, all anomalous points are known ahead of time. That means there are sets of data points that are anomalous, but are not identified as such for the model to train on.\n",
    "\n",
    "Popular ML algorithms for structured data:\n",
    "\n",
    "* Support vector machine learning\n",
    "* k-nearest neighbors (KNN)\n",
    "* Bayesian networks\n",
    "* Decision trees\n",
    "\n",
    "### Unsupervised\n",
    "In Unsupervised settings, the training data is unlabeled and consists of “nominal” and “anomaly” points.\n",
    "\n",
    "The hardest case, and the ever-increasing case for modelers in the ever-increasing amounts of dark data, is the unsupervised instance. The datasets in the unsupervised case do not have their parts labeled as nominal or anomalous. There is no ground truth from which to expect the outcome to be. The model must show the modeler what is anomalous and what is nominal.\n",
    "\n",
    "<i>“The most common tasks within unsupervised learning are clustering, representation learning, and density estimation. In all of these cases, we wish to learn the inherent structure of our data without using explicitly-provided labels.”- Devin Soni</i>\n",
    "\n",
    "Popular ML Algorithms for unstructured data are:\n",
    "\n",
    "* Self-organizing maps (SOM)\n",
    "* K-means\n",
    "* C-means\n",
    "* Expectation-maximization meta-algorithm (EM)\n",
    "* Adaptive resonance theory (ART)\n",
    "* One-class support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac3227",
   "metadata": {},
   "source": [
    "Let’s see the some of the most popular anomaly detection algorithms.\n",
    "\n",
    "1. K-nearest neighbor: k-NN\n",
    "\n",
    "k-NN is one of the simplest supervised learning algorithms and methods in machine learning. It stores all of the available examples and then classifies the new ones based on similarities in distance metrics.\n",
    "\n",
    "k-NN is a famous classification algorithm and a lazy learner. What does a lazy learner mean?\n",
    "\n",
    "K-nearest neighbor mainly stores the training data. It doesn’t do anything else during the training process. That’ s why it is lazy.\n",
    "\n",
    "k-NN just stores the labeled training data. When new unlabeled data arrives, kNN works in 2 main steps:\n",
    "\n",
    "Looks at the k closest training data points (the k-nearest neighbors).\n",
    "Then, as it uses the k-nearest neighbors, k-NN decides how the new data should be classified.\n",
    "How does k-NN know what’s closer?\n",
    "\n",
    "It uses density-based anomaly detection methods. For continuous data (see continuous vs discrete data), the most common distance measure is the Euclidean distance. For discrete data, Hamming distance is a popular metric for the “closeness” of 2 text strings.\n",
    "\n",
    "The pick of distance metric depends on the data.\n",
    "\n",
    "The k-NN algorithm works very well for dynamic environments where frequent updates are needed. In addition, density-based distance measures are good solutions for identifying unusual conditions and gradual trends. This makes k-NN useful for outlier detection and defining suspicious events.\n",
    "\n",
    "k-NN also is very good techniques for creating models that involve non-standard data types like text.\n",
    "\n",
    "k-NN is one of the proven anomaly detection algorithms that increase the fraud detection rate. It is also one of the most known text mining algorithms out there.\n",
    "\n",
    "It has many applications in business and finance field. For example, k-NN helps for detecting and preventing credit card fraudulent transactions.\n",
    "\n",
    "2. Local Outlier Factor (LOF)\n",
    "\n",
    "The LOF is a key anomaly detection algorithm based on a concept of a local density. It uses the distance between the k nearest neighbors to estimate the density.\n",
    "\n",
    "LOF compares the local density of an item to the local densities of its neighbors. Thus one can determine areas of similar density and items that have a significantly lower density than their neighbors. These are the outliers.\n",
    "\n",
    "To put it in other words, the density around an outlier item is seriously different from the density around its neighbors.\n",
    "\n",
    "That is why LOF is called a density-based outlier detection algorithm. In addition, as you see, LOF is the nearest neighbors technique as k-NN.\n",
    "\n",
    "LOF is computed on the base of the average ratio of the local reachability density of an item and its k-nearest neighbors.\n",
    "\n",
    "3. K-means\n",
    "\n",
    "K-means is a very popular clustering algorithm in the data mining area. It creates k groups from a set of items so that the elements of a group are more similar.\n",
    "\n",
    "Just to recall that cluster algorithms are designed to make groups where the members are more similar. In this term, clusters and groups are synonymous.\n",
    "\n",
    "In K-means technique, data items are clustered depending on feature similarity.\n",
    "\n",
    "One of the greatest benefits of k-means is that it is very easy to implement. K-means is successfully implemented in the most of the usual programming languages that data science uses.\n",
    "\n",
    "If you are going to use k-means for anomaly detection, you should take in account some things:\n",
    "\n",
    "The user has to define the number of clusters in the early beginning.\n",
    "k-means suppose that each cluster has pretty equal numbers of observations.\n",
    "k-means only work with numerical data.\n",
    "Is k-means supervised or unsupervised? It depends, but most data science specialists classify it as unsupervised. The reason is that, besides specifying the number of clusters, k-means “learns” the clusters on its own. k-means can be semi-supervised.\n",
    "\n",
    "4. Support Vector Machine (SVM)\n",
    "\n",
    "A support vector machine is also one of the most effective anomaly detection algorithms. SVM is a supervised machine learning technique mostly used in classification problems.\n",
    "\n",
    "It uses a hyperplane to classify data into 2 different groups.\n",
    "\n",
    "Just to recall that hyperplane is a function such as a formula for a line (e.g. y = nx + b).\n",
    "\n",
    "SVM determines the best hyperplane that separates data into 2 classes.\n",
    "\n",
    "To say it in another way, given labeled learning data, the algorithm produces an optimal hyperplane that categorizes the new examples.\n",
    "\n",
    "When it comes to anomaly detection, the SVM algorithm clusters the normal data behavior using a learning area. Then, using the testing example, it identifies the abnormalities that go out of the learned area.\n",
    "\n",
    "5. Neural Networks Based Anomaly Detection\n",
    "\n",
    "When it comes to modern anomaly detection algorithms, we should start with neural networks.\n",
    "\n",
    "Artificial neural networks are quite popular algorithms initially designed to mimic biological neurons.\n",
    "\n",
    "The primary goal of creating a system of artificial neurons is to get systems that can be trained to learn some data patterns and execute functions like classification, regression, prediction and etc.\n",
    "\n",
    "Building a recurrent neural network that discovers anomalies in time series data is a hot topic in data mining world today.\n",
    "\n",
    "What makes them very helpful for anomaly detection in time series is this power to find out dependent features in multiple time steps.\n",
    "\n",
    "There are many different types of neural networks and they have both supervised and unsupervised learning algorithms. Example of how neural networks can be used for anomaly detection, you can see here.\n",
    "\n",
    "The above 5 anomaly detection algorithms are the key ones. However, there are other techniques. Here is a more comprehensive list of techniques and algorithms.\n",
    "\n",
    "[Source](https://www.intellspot.com/anomaly-detection-algorithms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70495af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv', encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec21a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.InvoiceDate = pd.to_datetime(data.InvoiceDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date and select first 100 000 elements\n",
    "df = data.sort_values(by=[\"InvoiceDate\"])[:100001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef399a",
   "metadata": {},
   "source": [
    "### Z-Score (Similar Techniques: IQR based, Percentile based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity'] = df['Quantity'][df['Quantity'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ad7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.distplot(df['Quantity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ca774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score with mean or median\n",
    "upper_limit = df.Quantity.mean() + 3*df.Quantity.std()\n",
    "lower_limit = df.Quantity.mean() - 3*df.Quantity.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ebfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Highest allowed\",upper_limit)\n",
    "print(\"Lowest allowed\",lower_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_free_df = df[(df.Quantity < upper_limit) & (df.Quantity > lower_limit)]\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(outlier_free_df.Quantity)\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(data=outlier_free_df, x=\"InvoiceDate\", y=\"Quantity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9764613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score outlier detection\n",
    "def calculate_z_score(X:list) -> list: \n",
    "    return np.abs(np.array(X) - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zscore'] = calculate_z_score(df.Quantity)\n",
    "df = df[df['zscore']<3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3150df8",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# dbscan_data = data[['Quantity', 'UnitPrice']][:1000]\n",
    "dbscan_data = df[['Quantity', 'UnitPrice']][:1000]\n",
    "\n",
    "# DBSCAN model with parameters\n",
    "model = DBSCAN().fit(dbscan_data)\n",
    "\n",
    "# Scatter plot function\n",
    "colors = model.labels_\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.scatter(dbscan_data.Quantity, dbscan_data.UnitPrice, c=colors)\n",
    "plt.xlabel('Quantity', fontsize=16)\n",
    "plt.ylabel('UnitePrice', fontsize=16)\n",
    "plt.title('Quantity vs UNitPrice', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers \n",
    "target = dbscan_data.Quantity\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(target.values, bins=50, label='Quantity')\n",
    "plt.axvline(np.mean(target.values), ls='--', c='r', label=\"Mean\")\n",
    "plt.axvline(np.median(target.values), ls=':', c='g', label=\"Median\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Quantity\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(target, np.random.normal(7, 0.2, size=target.shape[0]), alpha=0.5)\n",
    "plt.title(\"Quantity\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x=dbscan_data.Quantity)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.violinplot(x=dbscan_data.Quantity, inner=\"quartile\", bw=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074be07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
